{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aff0c188-9d57-4cb4-8ce5-0d2fd96d7f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EvalPrediction\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a905715a-a265-4988-803f-49dabec04094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "file_path = 'F:\\\\finetunining sample\\\\combined_dataset.csv'\n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Initialize the tokenizer\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c06d85e2-06e3-4421-935f-448ac0ad17ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "priority_binned\n",
       "Low       10912\n",
       "Medium     9405\n",
       "High       2335\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['priority_binned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9203526-8ea1-48e8-98ee-fe46eddd25cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bug_resolution_time\n",
       "Short-Term     9118\n",
       "Long-Term      8933\n",
       "Medium-Term    4601\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset['bug_resolution_time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9320801-3bec-4230-95d7-75cdaa30805b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3240b218-9355-4a34-b6f3-22d4f66e4954",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = dataset[((dataset['bug_resolution_time'] ==\"Short-Term\") | (dataset['bug_resolution_time'] ==\"Long-Term\")) & ((dataset['priority_binned'] ==\"Low\") | (dataset['priority_binned'] ==\"Medium\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7061fe58-10f1-4a05-bbf4-1b3c6bde0fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "priority_binned\n",
       "Low       8786\n",
       "Medium    7387\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val['priority_binned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bbbb95b-7eb1-4738-a690-92b683aaf46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bug_resolution_time\n",
       "Short-Term    8104\n",
       "Long-Term     8069\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val['bug_resolution_time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fef0ae7a-1c8c-4f33-a4f9-078eda6a1336",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.to_csv(\"updated_combined_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f76c3dd-379f-4887-90a2-62e414aefcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Add “int-kafka:message-driven-channel-adapter” graphic to integration-graph tab'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.iloc[441]['input_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ee89588-8fee-4eab-8cf1-16524850d5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Lowercasing\n",
    "dataset['input_text'] = dataset['input_text'].str.lower()\n",
    "\n",
    "# Step 2: Remove unnecessary special characters but keep numbers and meaningful punctuation\n",
    "dataset['input_text'] = dataset['input_text'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s.,!?]', '', x))\n",
    "\n",
    "# Step 3: Tokenization\n",
    "dataset['input_text_tokens'] = dataset['input_text'].apply(lambda x: tokenizer.tokenize(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc9ad8da-b20f-4344-ae2c-766dba08d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Padding/Truncation\n",
    "max_length = 128\n",
    "dataset['input_text_padded'] = dataset['input_text_tokens'].apply(\n",
    "    lambda x: tokenizer.convert_tokens_to_ids(x)[:max_length] + [0] * (max_length - len(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d59a818a-6a33-4c83-abbb-2cf443769891",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the target variables\n",
    "label_encoder_priority = LabelEncoder()\n",
    "label_encoder_resolution = LabelEncoder()\n",
    "\n",
    "dataset['priority_encoded'] = label_encoder_priority.fit_transform(dataset['priority_binned'])\n",
    "dataset['resolution_encoded'] = label_encoder_resolution.fit_transform(dataset['bug_resolution_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dd47268-ad76-4666-8a18-ae15c41b03be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train, validation, and test sets\n",
    "train_df, test_df = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab4bc6bd-d506-4705-81f7-49def7a21cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to tensors\n",
    "def convert_to_tensor(df, feature_col, target_col):\n",
    "    features = torch.tensor(df[feature_col].tolist(), dtype=torch.long)\n",
    "    targets = torch.tensor(df[target_col].tolist(), dtype=torch.long)\n",
    "    return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b9b6069-b2da-4ff7-9087-4f4bd9b230ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_priority = convert_to_tensor(train_df, 'input_text_padded', 'priority_encoded')\n",
    "train_features, train_resolution = convert_to_tensor(train_df, 'input_text_padded', 'resolution_encoded')\n",
    "\n",
    "val_features, val_priority = convert_to_tensor(val_df, 'input_text_padded', 'priority_encoded')\n",
    "val_features, val_resolution = convert_to_tensor(val_df, 'input_text_padded', 'resolution_encoded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbcc8673-92d2-40aa-8d70-5d01747a2a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorDataset instances\n",
    "train_dataset = TensorDataset(train_features, train_priority, train_resolution)\n",
    "val_dataset = TensorDataset(val_features, val_priority, val_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00a0adb5-2afb-4d70-8869-a47f6172d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define compute_metrics_function\n",
    "def compute_metrics_function(eval_pred: EvalPrediction):\n",
    "    predictions = eval_pred.predictions.argmax(axis=-1)  # Convert logits to predicted labels\n",
    "    labels = eval_pred.label_ids\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67b43b0b-b2f4-48dd-a4c9-8a4e403153f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "vars() argument must have __dict__ attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 25\u001b[0m\n\u001b[0;32m     16\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     17\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     18\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics_function,  \u001b[38;5;66;03m# Define a function for evaluation metrics\u001b[39;00m\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\test_env\\lib\\site-packages\\transformers\\trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1860\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\test_env\\lib\\site-packages\\transformers\\trainer.py:2165\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2162\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2164\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 2165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[0;32m   2166\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39minclude_num_input_tokens_seen:\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\test_env\\lib\\site-packages\\accelerate\\data_loader.py:452\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 452\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\test_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\test_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\test_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\test_env\\lib\\site-packages\\transformers\\trainer_utils.py:808\u001b[0m, in \u001b[0;36mRemoveColumnsCollator.__call__\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[\u001b[38;5;28mdict\u001b[39m]):\n\u001b[0;32m    807\u001b[0m     features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remove_columns(feature) \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[1;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\test_env\\lib\\site-packages\\transformers\\data\\data_collator.py:92\u001b[0m, in \u001b[0;36mdefault_data_collator\u001b[1;34m(features, return_tensors)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# In this function we'll make the assumption that all `features` in the batch\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# have the same attributes.\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# So we will look at the first element as a proxy for what attributes exist\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# on the whole batch.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_default_data_collator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_tensors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf_default_data_collator(features)\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\test_env\\lib\\site-packages\\transformers\\data\\data_collator.py:131\u001b[0m, in \u001b[0;36mtorch_default_data_collator\u001b[1;34m(features)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(features[\u001b[38;5;241m0\u001b[39m], Mapping):\n\u001b[1;32m--> 131\u001b[0m     features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mvars\u001b[39m(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[0;32m    132\u001b[0m first \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    133\u001b[0m batch \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\test_env\\lib\\site-packages\\transformers\\data\\data_collator.py:131\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(features[\u001b[38;5;241m0\u001b[39m], Mapping):\n\u001b[1;32m--> 131\u001b[0m     features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[0;32m    132\u001b[0m first \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    133\u001b[0m batch \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mTypeError\u001b[0m: vars() argument must have __dict__ attribute"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained model and modify for multi-output classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',                # Directory to save model checkpoints\n",
    "    evaluation_strategy='epoch',           # Evaluate at the end of each epoch\n",
    "    learning_rate=2e-5,                    # Learning rate\n",
    "    per_device_train_batch_size=32,        # Batch size for training\n",
    "    per_device_eval_batch_size=32,         # Batch size for evaluation\n",
    "    num_train_epochs=3,                    # Number of training epochs\n",
    "    weight_decay=0.01,                     # Weight decay for regularization\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics_function,  # Define a function for evaluation metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e92d58d9-de1d-40b0-8772-22387dfff776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\E009819\\AppData\\Local\\miniconda3\\envs\\test_env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\E009819\\AppData\\Local\\miniconda3\\envs\\test_env\\lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: vars() argument must have __dict__ attribute\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EvalPrediction\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Load your dataset\n",
    "file_path = 'F:\\\\finetunining sample\\\\combined_dataset.csv'\n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Step 1: Lowercasing\n",
    "dataset['input_text'] = dataset['input_text'].str.lower()\n",
    "\n",
    "# Step 2: Remove unnecessary special characters but keep numbers and meaningful punctuation\n",
    "dataset['input_text'] = dataset['input_text'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s.,!?]', '', x))\n",
    "\n",
    "# Step 3: Tokenization\n",
    "dataset['input_text_tokens'] = dataset['input_text'].apply(lambda x: tokenizer.tokenize(x))\n",
    "\n",
    "# Step 4: Padding/Truncation\n",
    "max_length = 128\n",
    "dataset['input_text_padded'] = dataset['input_text_tokens'].apply(\n",
    "    lambda x: tokenizer.convert_tokens_to_ids(x)[:max_length] + [0] * (max_length - len(x))\n",
    ")\n",
    "\n",
    "# Encode the target variables\n",
    "label_encoder_priority = LabelEncoder()\n",
    "label_encoder_resolution = LabelEncoder()\n",
    "\n",
    "dataset['priority_encoded'] = label_encoder_priority.fit_transform(dataset['priority_binned'])\n",
    "dataset['resolution_encoded'] = label_encoder_resolution.fit_transform(dataset['bug_resolution_time'])\n",
    "\n",
    "# Split dataset into train, validation, and test sets\n",
    "train_df, test_df = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert columns to tensors\n",
    "def convert_to_tensor(df, feature_col, target_col):\n",
    "    features = torch.tensor(df[feature_col].tolist(), dtype=torch.long)\n",
    "    targets = torch.tensor(df[target_col].tolist(), dtype=torch.long)\n",
    "    return features, targets\n",
    "\n",
    "train_features, train_priority = convert_to_tensor(train_df, 'input_text_padded', 'priority_encoded')\n",
    "train_features, train_resolution = convert_to_tensor(train_df, 'input_text_padded', 'resolution_encoded')\n",
    "\n",
    "val_features, val_priority = convert_to_tensor(val_df, 'input_text_padded', 'priority_encoded')\n",
    "val_features, val_resolution = convert_to_tensor(val_df, 'input_text_padded', 'resolution_encoded')\n",
    "\n",
    "# Create TensorDataset instances\n",
    "train_dataset = TensorDataset(train_features, train_priority, train_resolution)\n",
    "val_dataset = TensorDataset(val_features, val_priority, val_resolution)\n",
    "\n",
    "# Define compute_metrics_function\n",
    "def compute_metrics_function(eval_pred: EvalPrediction):\n",
    "    predictions = eval_pred.predictions.argmax(axis=-1)  # Convert logits to predicted labels\n",
    "    labels = eval_pred.label_ids\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "# Load a pre-trained model and modify for multi-output classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',                # Directory to save model checkpoints\n",
    "    evaluation_strategy='epoch',           # Evaluate at the end of each epoch\n",
    "    learning_rate=2e-5,                    # Learning rate\n",
    "    per_device_train_batch_size=64,        # Batch size for training\n",
    "    per_device_eval_batch_size=64,         # Batch size for evaluation\n",
    "    num_train_epochs=3,                    # Number of training epochs\n",
    "    weight_decay=0.01,                     # Weight decay for regularization\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics_function,  # Define a function for evaluation metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "try:\n",
    "    trainer.train()\n",
    "except TypeError as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d3691-8789-42b0-b592-eb2c9540e2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e1d8fb-a11a-41d9-a096-47b038026bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
