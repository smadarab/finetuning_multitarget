{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ba0e9ad-b2fe-437c-b71a-f41a02a4aa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\E009819\\AppData\\Local\\miniconda3\\envs\\test_env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(\"combined_dataset.csv\")\n",
    "\n",
    "# Initialize BERT tokenizer and model, moving the model to the GPU\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "# Function to generate embeddings using BERT on GPU\n",
    "def get_embeddings(text):\n",
    "    # Tokenize the input text and move tensors to GPU\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=128).to(device)\n",
    "    outputs = model(**inputs)\n",
    "    # Take the average of the token embeddings and move the result back to CPU\n",
    "    embeddings = torch.mean(outputs.last_hidden_state, dim=1).detach().cpu().numpy()\n",
    "    return embeddings[0]\n",
    "\n",
    "# Generate embeddings for the entire dataset\n",
    "data['embeddings'] = data['input_text'].apply(get_embeddings)\n",
    "\n",
    "# Encode the target labels and combine them into a single column\n",
    "combined_target = data['priority_binned'] + \"_\" + data['bug_resolution_time']\n",
    "\n",
    "# Encode combined target using LabelEncoder\n",
    "le_combined = LabelEncoder()\n",
    "combined_target_encoded = le_combined.fit_transform(combined_target)\n",
    "\n",
    "# Prepare the embeddings as features\n",
    "X = np.stack(data['embeddings'].values)\n",
    "\n",
    "# Apply SMOTE to the combined target\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, combined_target_encoded)\n",
    "\n",
    "# Decode the combined target back into separate priority and resolution time columns\n",
    "combined_res = le_combined.inverse_transform(y_res)\n",
    "priority_res, resolution_res = zip(*[item.split(\"_\") for item in combined_res])\n",
    "\n",
    "# Create a DataFrame for synthetic samples\n",
    "synthetic_data = pd.DataFrame(X_res, columns=[f'embedding_{i}' for i in range(X_res.shape[1])])\n",
    "synthetic_data['priority_binned'] = priority_res\n",
    "synthetic_data['bug_resolution_time'] = resolution_res\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62f23d7c-f042-4856-9c33-7e667e4f356d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['embedding_0', 'embedding_1', 'embedding_2', 'embedding_3',\n",
       "       'embedding_4', 'embedding_5', 'embedding_6', 'embedding_7',\n",
       "       'embedding_8', 'embedding_9',\n",
       "       ...\n",
       "       'embedding_760', 'embedding_761', 'embedding_762', 'embedding_763',\n",
       "       'embedding_764', 'embedding_765', 'embedding_766', 'embedding_767',\n",
       "       'priority_binned', 'bug_resolution_time'],\n",
       "      dtype='object', length=770)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f08c2ac-8541-46c0-b948-96fcfd98ab58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
